{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FPNN:\n",
    "    def __init__(self, sigma=8):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def train(self, train_data, train_labels, batch_size=256):\n",
    "        train_data = tf.convert_to_tensor(train_data)\n",
    "        train_labels = tf.convert_to_tensor(train_labels)\n",
    "    \n",
    "        # how do I load batches pls\n",
    "        train_image_batch, train_label_batch = tf.train.shuffle_batch([train_data, train_labels],batch_size=BATCH_SIZE)\n",
    "        \n",
    "        \n",
    "        ## HARD THINGS ##\n",
    "        # field probing https://github.com/yangyanli/caffe/blob/field_probing/src/caffe/layers/field_probing_layer.cpp\n",
    "        # rotation z? https://github.com/yangyanli/caffe/blob/field_probing/src/caffe/layers/transform_3d_layer.cpp\n",
    "        # gaussian https://github.com/yangyanli/caffe/blob/field_probing/src/caffe/layers/gaussian_layer.cpp\n",
    "        # dot product https://github.com/yangyanli/caffe/blob/field_probing/src/caffe/layers/dot_product_layer.cpp\n",
    "        \n",
    "        ## EASY THINGS ##\n",
    "        # batch norm\n",
    "        # relu\n",
    "        # fc0\n",
    "        # batch norm\n",
    "        # relu\n",
    "        # dropout\n",
    "        # fc1\n",
    "        # batch norm\n",
    "        # relu\n",
    "        # dropout\n",
    "        # fc2\n",
    "        # batch norm\n",
    "        # relu\n",
    "        # dropout\n",
    "        # fc3\n",
    "        # softmax and accuracy\n",
    "        ## BELOW ##\n",
    "        \n",
    "        bn_dp = tf.contrib.layers.batch_norm(dp, center=True, scale=True, is_training = True, name='bn_dp')\n",
    "        relu_dp = tf.nn.relu(bn_dp, name='relu_dp')\n",
    "        \n",
    "        fc0 = fc_layer(relu_dp, 'fc0', 1024)\n",
    "        bn0 = tf.contrib.layers.batch_norm(fc0, center=True, scale=True, is_training = True, name='bn_0')\n",
    "        relu0 = tf.nn.relu(bn0, name='relu0')\n",
    "        dropout0 = tf.nn.dropout(relu0, keep_prob = 0.5, name='dropout0')\n",
    "        fc1 = fc_layer(dropout0, 'fc1', 1024)\n",
    "        bn1 = tf.contrib.layers.batch_norm(fc1, center=True, scale=True, is_training = True, name='bn_1')\n",
    "        relu1 = tf.nn.relu(bn1, name='relu1')\n",
    "        dropout1 = tf.nn.dropout(relu1, keep_prob = 0.5, name='dropout1')\n",
    "        fc2 = fc_layer(dropout1, 'fc2', 1024)\n",
    "        bn2 = tf.contrib.layers.batch_norm(fc2, center=True, scale=True, is_training = True, name='bn_2')\n",
    "        relu2 = tf.nn.relu(bn2, name='relu2')\n",
    "        dropout2 = tf.nn.dropout(relu2, keep_prob = 0.5, name='dropout2')\n",
    "        fc3 = fc_layer(dropout2, 'fc3', 40, 0)\n",
    "        \n",
    "        y_hat = tf.nn.softmax(fc3, name='prob')\n",
    "    \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=fc3, labels=train_label_batch))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_hat, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        # run tf session and save\n",
    "        \n",
    "    def fc_layer(bottom, name, num, intial_bias=1):\n",
    "        with tf.variable_scope(name):\n",
    "            shape = bottom.get_shape().as_list()\n",
    "            dim = 1\n",
    "            for d in shape[1:]:\n",
    "                dim *= d\n",
    "            x = tf.reshape(bottom, [-1, dim])\n",
    "\n",
    "            weights = tf.Variable(tf.truncated_normal([dim, num], stddev=0.05), name='weights')\n",
    "            if initial_bias:\n",
    "                biases = tf.Variable(tf.ones([num]), name='biases')\n",
    "            else:\n",
    "                biases = tf.Variable(tf.zeros([num]), name='biases')\n",
    "            fc = tf.nn.bias_add(tf.matmul(x, weights), biases)\n",
    "\n",
    "            return fc    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def test(self, test_data):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
